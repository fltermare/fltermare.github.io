<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>GPU - Tag - FLTERMARE&#39;s NOTE</title>
        <link>https://fltermare.tw/tags/gpu/</link>
        <description>GPU - Tag - FLTERMARE&#39;s NOTE</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 12 Jun 2020 22:16:22 &#43;0000</lastBuildDate><atom:link href="https://fltermare.tw/tags/gpu/" rel="self" type="application/rss+xml" /><item>
    <title>Environment Setup (Docker &#43; Tensorflow &#43; Mxnet &#43; GPU)</title>
    <link>https://fltermare.tw/2020/06/docker-x-tensorflow-x-mxnet-x-gpu/</link>
    <pubDate>Fri, 12 Jun 2020 22:16:22 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://fltermare.tw/2020/06/docker-x-tensorflow-x-mxnet-x-gpu/</guid>
    <description><![CDATA[前言 先前的經驗告訴我，建個 GPU 訓練環境是很麻煩的事
最近想學習一下 Computer Vision，是時候再來弄個環境
原先在猜，如果用 container 的方式來做說不定會比較簡單，也容易搬到別的地方部屬
結果，還是有不少眉眉角角的地方要注意
目前看來，應該有比較好 deploy 吧？
Pre-installation 簡單說明安裝前的環境
 Ubuntu 18.04 LTS Docker version 19.03.11 GPU (1070ti)  1 2  接下來，文章中會用 Host 代表所謂的 Localhost (本機)， Guest 代表 Container 我不確定這用法是否合適，若有更好的說法，請再指教 :)   可以看到，Host 還沒有裝 nvidia-driver 跟 CUDA
實際上，Host 不用刻意去裝 CUDA。之後直接 pull 別人處理好的 image 就行。
除非，你想在 Host 也有個可以使用 GPU training 的環境。
Docker的部份請參考 https://docs.docker.com/engine/install/ubuntu/
除非像敝司的網路環境，什麼都要設定 Proxy，不然這官網這一頁就很夠了
Installation Nvidia Driver  先檢查是否有 ubuntu-drivers-common 這個工具 (我的環境是已安裝)]]></description>
</item></channel>
</rss>
